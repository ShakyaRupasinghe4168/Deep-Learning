{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Lab: Building Advanced Transformers**\n",
    "\n",
    "**Estimated time needed:  30 minutes**  \n",
    "\n",
    "In this lab, you will implement and experiment with advanced Transformer models using Keras. \n",
    "\n",
    "**Learning objectives:** \n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "- Understand the core components of a Transformer architecture.\n",
    "- Implement a multi-head self-attention mechanism from scratch.\n",
    "- Train and evaluate a Transformer for time series prediction.\n",
    "- Handle preprocessing and scaling for time series data effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Transformer?\n",
    "\n",
    "The Transformer architecture was introduced in the paper *\"Attention Is All You Need\"*. It revolutionized natural language processing by using attention mechanisms instead of recurrence.\n",
    "\n",
    "### Key Components:\n",
    "- **Input Embedding:** Converts input tokens (or time steps) into vectors.\n",
    "- **Positional Encoding:** Injects information about the position of input tokens.\n",
    "- **Multi-Head Self-Attention:** Allows the model to focus on different parts of the input sequence.\n",
    "- **Feedforward Layers:** Process the attended information.\n",
    "- **Layer Normalization & Residual Connections:** Stabilize and speed up training.\n",
    "\n",
    "> Transformers are now widely used not only in NLP but also in time series forecasting, image recognition, and more.\n",
    "\n",
    "**Next:** You will implement parts of this architecture step-by-step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-Step Instructions: \n",
    "\n",
    "### Step 1: Import necessary libraries \n",
    "\n",
    "Before you start, you need to import the required libraries: TensorFlow and Keras. Keras is included within TensorFlow as `tensorflow.keras.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: pyarrow in /opt/conda/lib/python3.12/site-packages (22.0.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (6.33.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.0.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.3.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow pyarrow \n",
    "%pip install pandas  \n",
    "%pip install scikit-learn \n",
    "%pip install matplotlib \n",
    "%pip install requests\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 16:10:11.387086: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-05 16:10:11.387553: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-05 16:10:11.451750: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-05 16:10:13.160540: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-11-05 16:10:13.161323: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "import requests\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Setup the Environment to generate synthetic stock price data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthetic stock_prices.csv created and loaded.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a synthetic stock price dataset\n",
    "np.random.seed(42)\n",
    "data_length = 2000  # Adjust data length as needed\n",
    "trend = np.linspace(100, 200, data_length)\n",
    "noise = np.random.normal(0, 2, data_length)\n",
    "synthetic_data = trend + noise\n",
    "\n",
    "# Create a DataFrame and save as 'stock_prices.csv'\n",
    "data = pd.DataFrame(synthetic_data, columns=['Close'])\n",
    "data.to_csv('stock_prices.csv', index=False)\n",
    "print(\"Synthetic stock_prices.csv created and loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (1899, 100, 1)\n",
      "Shape of Y: (1899,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset \n",
    "data = pd.read_csv('stock_prices.csv') \n",
    "data = data[['Close']].values \n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Prepare the data for training\n",
    "def create_dataset(data, time_step=1):\n",
    "    X, Y = [], []\n",
    "\n",
    "    for i in range(len(data)-time_step-1):\n",
    "        a = data[i:(i+time_step), 0]\n",
    "        X.append(a)\n",
    "        Y.append(data[i + time_step, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "time_step = 100\n",
    "X, Y = create_dataset(data, time_step)\n",
    "X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "\n",
    "print(\"Shape of X:\", X.shape) \n",
    "print(\"Shape of Y:\", Y.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "`tensorflow` is the main library for machine learning in Python.  \n",
    "\n",
    "`stock_prices.csv` is the data set that is loaded. \n",
    "\n",
    "`MinMaxScaler` method is used to normalize the data.  \n",
    "\n",
    "`create_dataset`method is used to prepare the data for training. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Implement Multi-Head Self-Attention \n",
    "\n",
    "Define the Multi-Head Self-Attention mechanism. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    "\n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The MultiHeadSelfAttention layer implements the multi-head self-attention mechanism, which allows the model to focus on different parts of the input sequence simultaneously. \n",
    "\n",
    "- The attention parameter computes the attention scores and weighted sum of the values. \n",
    "\n",
    "- The split_heads parameter splits the input into multiple heads for parallel attention computation. \n",
    "\n",
    "- The call method applies the self-attention mechanism and combines the heads. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Transformer block \n",
    "\n",
    "Define the Transformer block. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code:\n",
    "\n",
    "- The TransformerBlock layer combines multi-head self-attention with a feed-forward neural network and normalization layers.  \n",
    "\n",
    "- Dropout is used to prevent overfitting. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network with residual connections and layer normalization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Implement Encoder Layer \n",
    "\n",
    "Define the Encoder layer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(Layer): \n",
    "\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(EncoderLayer, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    "\n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The EncoderLayer is similar to the TransformerBlock but is a reusable layer in the Transformer architecture. \n",
    "\n",
    "- It consists of a MultiHeadSelfAttention mechanism followed by a feedforward neural network. \n",
    "\n",
    "- Both sub-layers have residual connections around them, and layer normalization is applied to the output of each sub-layer. \n",
    "\n",
    "- The call method applies the self-attention, followed by the feedforward network, with residual connections and layer normalization. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Implement Transformer encoder \n",
    "\n",
    "Define the Transformer Encoder. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-05 16:10:14.920276: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100, 128)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Layer, Dense, LayerNormalization, Dropout \n",
    "\n",
    "class MultiHeadSelfAttention(Layer): \n",
    "    def __init__(self, embed_dim, num_heads=8): \n",
    "        super(MultiHeadSelfAttention, self).__init__() \n",
    "        self.embed_dim = embed_dim \n",
    "        self.num_heads = num_heads \n",
    "        self.projection_dim = embed_dim // num_heads \n",
    "        self.query_dense = Dense(embed_dim) \n",
    "        self.key_dense = Dense(embed_dim) \n",
    "        self.value_dense = Dense(embed_dim) \n",
    "        self.combine_heads = Dense(embed_dim) \n",
    " \n",
    "\n",
    "    def attention(self, query, key, value): \n",
    "        score = tf.matmul(query, key, transpose_b=True) \n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32) \n",
    "        scaled_score = score / tf.math.sqrt(dim_key) \n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1) \n",
    "        output = tf.matmul(weights, value) \n",
    "        return output, weights \n",
    "\n",
    "\n",
    "    def split_heads(self, x, batch_size): \n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim)) \n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3]) \n",
    "\n",
    "\n",
    "    def call(self, inputs): \n",
    "        batch_size = tf.shape(inputs)[0] \n",
    "        query = self.query_dense(inputs) \n",
    "        key = self.key_dense(inputs) \n",
    "        value = self.value_dense(inputs) \n",
    "        query = self.split_heads(query, batch_size) \n",
    "        key = self.split_heads(key, batch_size) \n",
    "        value = self.split_heads(value, batch_size) \n",
    "        attention, _ = self.attention(query, key, value) \n",
    "        attention = tf.transpose(attention, perm=[0, 2, 1, 3]) \n",
    "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim)) \n",
    "        output = self.combine_heads(concat_attention) \n",
    "        return output \n",
    "\n",
    "class TransformerBlock(Layer): \n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerBlock, self).__init__() \n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads) \n",
    "        self.ffn = tf.keras.Sequential([ \n",
    "            Dense(ff_dim, activation=\"relu\"), \n",
    "            Dense(embed_dim), \n",
    "        ]) \n",
    "\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6) \n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6) \n",
    "        self.dropout1 = Dropout(rate) \n",
    "        self.dropout2 = Dropout(rate) \n",
    " \n",
    "\n",
    "    def call(self, inputs, training): \n",
    "        attn_output = self.att(inputs) \n",
    "        attn_output = self.dropout1(attn_output, training=training) \n",
    "        out1 = self.layernorm1(inputs + attn_output) \n",
    "        ffn_output = self.ffn(out1) \n",
    "        ffn_output = self.dropout2(ffn_output, training=training) \n",
    "        return self.layernorm2(out1 + ffn_output) \n",
    "\n",
    "class TransformerEncoder(Layer): \n",
    "    def __init__(self, num_layers, embed_dim, num_heads, ff_dim, rate=0.1): \n",
    "        super(TransformerEncoder, self).__init__() \n",
    "        self.num_layers = num_layers \n",
    "        self.embed_dim = embed_dim \n",
    "        self.enc_layers = [TransformerBlock(embed_dim, num_heads, ff_dim, rate) for _ in range(num_layers)] \n",
    "        self.dropout = Dropout(rate) \n",
    "\n",
    "    def call(self, inputs, training=False): \n",
    "        x = inputs \n",
    "        for i in range(self.num_layers): \n",
    "            x = self.enc_layers[i](x, training=training) \n",
    "        return x \n",
    "\n",
    "# Example usage \n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "inputs = tf.random.uniform((1, 100, embed_dim)) \n",
    "outputs = transformer_encoder(inputs, training=False)  # Use keyword argument for 'training' \n",
    "print(outputs.shape)  # Should print (1, 100, 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The TransformerEncoder is composed of multiple TransformerBlock layers, implementing the encoding part of the Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and Compile the Transformer model \n",
    "\n",
    "Integrate the Transformer Encoder into a complete model for sequential data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">793,088</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncoder</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,801</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │           \u001b[38;5;34m256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ transformer_encoder_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │       \u001b[38;5;34m793,088\u001b[0m │\n",
       "│ (\u001b[38;5;33mTransformerEncoder\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12800\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │        \u001b[38;5;34m12,801\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">806,145</span> (3.08 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m806,145\u001b[0m (3.08 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the necessary parameters \n",
    "\n",
    "embed_dim = 128 \n",
    "num_heads = 8 \n",
    "ff_dim = 512 \n",
    "num_layers = 4 \n",
    "\n",
    "# Define the Transformer Encoder \n",
    "transformer_encoder = TransformerEncoder(num_layers, embed_dim, num_heads, ff_dim) \n",
    "\n",
    "# Build the model \n",
    "input_shape = (X.shape[1], X.shape[2]) \n",
    "inputs = tf.keras.Input(shape=input_shape) \n",
    "\n",
    "# Project the inputs to the embed_dim \n",
    "x = tf.keras.layers.Dense(embed_dim)(inputs) \n",
    "encoder_outputs = transformer_encoder(x) \n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "outputs = tf.keras.layers.Dense(1)(flatten) \n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "# Compile the model \n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "# Summary of the model \n",
    "model.summary() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The Transformer Encoder model defines the necessary parameters, flattens the output, and ends with a dense layer to produce the final output.  \n",
    "\n",
    "- The model is then compiled with the Adam optimizer and mean squared error loss. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train the Transformer model \n",
    "\n",
    "Train the model on the prepared dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 964ms/step - loss: 3.8417 \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 989ms/step - loss: 0.1805\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 984ms/step - loss: 0.1546\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 970ms/step - loss: 0.2141\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 946ms/step - loss: 0.2088\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 954ms/step - loss: 0.1651\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 940ms/step - loss: 0.1306\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 941ms/step - loss: 0.1416\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 950ms/step - loss: 0.1852\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 951ms/step - loss: 0.1007\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 963ms/step - loss: 0.1082\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 950ms/step - loss: 0.0982\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 944ms/step - loss: 0.0737\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 954ms/step - loss: 0.0921\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 944ms/step - loss: 0.0747\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 933ms/step - loss: 0.0521\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 943ms/step - loss: 0.0413\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 925ms/step - loss: 0.0618\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 946ms/step - loss: 0.0381\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 934ms/step - loss: 0.0266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x72a62c65d460>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "The model is trained on the normalized stock price data for 20 epochs with a batch size of 32. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Evaluate and Make Predictions \n",
    "\n",
    "Evaluate the model's performance and make predictions on the dataset. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 284ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions \n",
    "predictions = model.predict(X) \n",
    "predictions = scaler.inverse_transform(predictions) \n",
    "\n",
    "# Prepare true values for comparison\n",
    "true_values = scaler.inverse_transform(data.reshape(-1, 1))\n",
    "\n",
    "# Plot the predictions vs true values\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(true_values, label='True Data') \n",
    "plt.plot(np.arange(time_step, time_step + len(predictions)), predictions, label='Predictions') \n",
    "plt.xlabel('Time') \n",
    "plt.ylabel('Stock Price') \n",
    "plt.legend() \n",
    "plt.title('Predictions vs True Data (Both Scaled Back)')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code: \n",
    "\n",
    "- The model's predictions are transformed back to the original scale using the inverse transform of the scaler. \n",
    "\n",
    "- The true data and predictions are plotted to visualize the model's performance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises: \n",
    "\n",
    " ### Exercise 1: Add dropout to the Transformer model \n",
    "\n",
    " **Objective: Understand how to add dropout layers to the Transformer model to prevent overfitting.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Add a dropout layer after the Flatten layer in the model. \n",
    "\n",
    "- Set the dropout rate to 0.5. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 973ms/step - loss: 2.6735 \n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 958ms/step - loss: 0.6912\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 906ms/step - loss: 0.2606\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 922ms/step - loss: 0.1062\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 941ms/step - loss: 0.0755\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 921ms/step - loss: 0.0558\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 937ms/step - loss: 0.0420\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 936ms/step - loss: 0.0434\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 939ms/step - loss: 0.0389\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 938ms/step - loss: 0.0356\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 944ms/step - loss: 0.0319\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 938ms/step - loss: 0.0282\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 946ms/step - loss: 0.0278\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 956ms/step - loss: 0.0215\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 947ms/step - loss: 0.0215\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 956ms/step - loss: 0.0157\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 933ms/step - loss: 0.0152\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 958ms/step - loss: 0.0139\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 933ms/step - loss: 0.0201\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 944ms/step - loss: 0.0148\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 271ms/step - loss: 5.5163e-04\n",
      "Test loss: 0.0005516260862350464\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "from tensorflow.keras.layers import Dropout \n",
    "\n",
    "  \n",
    "\n",
    "# Add a dropout layer after the Flatten layer \n",
    "\n",
    "flatten = tf.keras.layers.Flatten()(encoder_outputs) \n",
    "\n",
    "dropout = Dropout(0.5)(flatten) \n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(dropout) \n",
    "\n",
    "  \n",
    "\n",
    "# Build the model \n",
    "\n",
    "model = tf.keras.Model(inputs, outputs) \n",
    "\n",
    "  \n",
    "\n",
    "# Compile the model \n",
    "\n",
    "model.compile(optimizer='adam', loss='mse') \n",
    "\n",
    "  \n",
    "\n",
    "# Train the model \n",
    "\n",
    "model.fit(X, Y, epochs=20, batch_size=32) \n",
    "\n",
    "  \n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "loss = model.evaluate(X, Y) \n",
    "\n",
    "print(f'Test loss: {loss}') \n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Experiment with different batch sizes \n",
    "\n",
    "**Objective: Observe the impact of different batch sizes on model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Train the model with a batch size of 16. \n",
    "\n",
    "- Train the model with a batch size of 64. \n",
    "\n",
    "- Compare the training time and performance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 552ms/step - loss: 0.0203 \n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 559ms/step - loss: 0.0300 \n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 561ms/step - loss: 0.0197 \n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 558ms/step - loss: 0.0271 \n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 558ms/step - loss: 0.0524 \n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 563ms/step - loss: 0.0234 \n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 554ms/step - loss: 0.0256 \n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 555ms/step - loss: 0.0162 \n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 556ms/step - loss: 0.0239 \n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 559ms/step - loss: 0.0201 \n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 537ms/step - loss: 0.0134 \n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 544ms/step - loss: 0.0216 \n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 626ms/step - loss: 0.0136 \n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 766ms/step - loss: 0.0199 \n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 817ms/step - loss: 0.0212 \n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2s/step - loss: 0.0213   \n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 2s/step - loss: 0.0178\n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 2s/step - loss: 0.0106\n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m237s\u001b[0m 2s/step - loss: 0.0160\n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m228s\u001b[0m 2s/step - loss: 0.0112\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 1s/step - loss: 0.0039   \n",
      "Test loss with batch size 16: 0.0038530766032636166\n",
      "Epoch 1/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - loss: 0.0084\n",
      "Epoch 2/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m153s\u001b[0m 5s/step - loss: 0.0044\n",
      "Epoch 3/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 5s/step - loss: 0.0036\n",
      "Epoch 4/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - loss: 0.0030\n",
      "Epoch 5/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 5s/step - loss: 0.0032\n",
      "Epoch 6/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 5s/step - loss: 0.0031  \n",
      "Epoch 7/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 5s/step - loss: 0.0029\n",
      "Epoch 8/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - loss: 0.0029\n",
      "Epoch 9/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - loss: 0.0026\n",
      "Epoch 10/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 5s/step - loss: 0.0024\n",
      "Epoch 11/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - loss: 0.0037\n",
      "Epoch 12/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 5s/step - loss: 0.0026\n",
      "Epoch 13/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 5s/step - loss: 0.0024\n",
      "Epoch 14/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 5s/step - loss: 0.0028\n",
      "Epoch 15/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 5s/step - loss: 0.0027  \n",
      "Epoch 16/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 5s/step - loss: 0.0027\n",
      "Epoch 17/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 5s/step - loss: 0.0023\n",
      "Epoch 18/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 5s/step - loss: 0.0025\n",
      "Epoch 19/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m148s\u001b[0m 5s/step - loss: 0.0024\n",
      "Epoch 20/20\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 3s/step - loss: 0.0027 \n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 1s/step - loss: 8.2314e-04   \n",
      "Test loss with batch size 64: 0.0008231393876485527\n"
     ]
    }
   ],
   "source": [
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Train the model with batch size 16\n",
    "model.fit(X, Y, epochs=20, batch_size=16)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 16: {loss}')\n",
    "\n",
    "# Train the model with batch size 64\n",
    "model.fit(X, Y, epochs=20, batch_size=64)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with batch size 64: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: Use a different activation function \n",
    "\n",
    " **Objective: Understand how different activation functions impact the model performance.** \n",
    "\n",
    " Instructions: \n",
    "\n",
    "- Change the activation function of the Dense layer to `tanh`. \n",
    "\n",
    "- Train and evaluate the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m223s\u001b[0m 3s/step - loss: 0.3080\n",
      "Epoch 2/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 2s/step - loss: 0.2967\n",
      "Epoch 3/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 4/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 5/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 6/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m194s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 7/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 3s/step - loss: 0.2986\n",
      "Epoch 8/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 9/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 10/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m191s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 11/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 12/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 13/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 14/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 15/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 16/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m196s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 17/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 18/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 19/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m192s\u001b[0m 3s/step - loss: 0.2967\n",
      "Epoch 20/20\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 3s/step - loss: 0.2967\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 1s/step - loss: 0.2967 \n",
      "Test loss with tanh activation: 0.29668867588043213\n"
     ]
    }
   ],
   "source": [
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Click here to view the solution.</summary>\n",
    "\n",
    "```\n",
    "# Change the activation function of the Dense layer to tanh\n",
    "outputs = tf.keras.layers.Dense(1, activation='tanh')(flatten)\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=20, batch_size=32)\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X, Y)\n",
    "print(f'Test loss with tanh activation: {loss}')\n",
    "\n",
    "```\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this lab! In this lab, you have built an advanced Transformer model using Keras and applied it to a time series forecasting task. You have learned how to define and implement multi-head self-attention, Transformer blocks, encoder layers, and integrate them into a complete Transformer model. By experimenting with different configurations and training the model, you can further improve its performance and apply it to various sequential data tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright © IBM Corporation. All rights reserved.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  },
  "prev_pub_hash": "8aae4de69f29de06e63c5f2d04ef24811d42d1553c8ac316f7ad75d55f2c2d79"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
